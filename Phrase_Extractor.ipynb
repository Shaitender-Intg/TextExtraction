{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "#import pickle to dump extracted features \n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sents</th>\n",
       "      <th>Terms</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>acquittal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>judgement</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>defendant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>volutpat at tellus at urna condimentum mattis ...</td>\n",
       "      <td>affidavit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>or officer having authority to administer oath...</td>\n",
       "      <td>appellate</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Sents      Terms\n",
       "0                                                NaN  acquittal\n",
       "1                                                NaN  judgement\n",
       "2                                                NaN  defendant\n",
       "3  volutpat at tellus at urna condimentum mattis ...  affidavit\n",
       "4  or officer having authority to administer oath...  appellate"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./terms_with_sentences.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "court                 51\n",
       "jury                  16\n",
       "judge                 15\n",
       "evidence              13\n",
       "defendant             13\n",
       "lawsuit                9\n",
       "appellate              8\n",
       "testimony              7\n",
       "judgement              7\n",
       "answer                 7\n",
       "parties                7\n",
       "witness                6\n",
       "plaintiff              5\n",
       "complaint              5\n",
       "opinion                4\n",
       "record                 4\n",
       "bankruptcy             4\n",
       "appeal                 4\n",
       "jurisdiction           3\n",
       "petit jury             3\n",
       "transcript             3\n",
       "discovery              3\n",
       "clerk of court         2\n",
       "remand                 2\n",
       "settlement             2\n",
       "issue                  2\n",
       "warrant                2\n",
       "reverse                2\n",
       "mistrial               2\n",
       "brief                  2\n",
       "                      ..\n",
       "jurisprudence          1\n",
       "case law               1\n",
       "charge to the jury     1\n",
       "conviction             1\n",
       "arraignment            1\n",
       "sidebar                1\n",
       "common law             1\n",
       "oral argument          1\n",
       "counterclaim           1\n",
       "capital offense        1\n",
       "contract               1\n",
       "default judgement      1\n",
       "venue                  1\n",
       "damages                1\n",
       "bail                   1\n",
       "agreement              1\n",
       "federal question       1\n",
       "summary judgement      1\n",
       "sequester              1\n",
       "uphold                 1\n",
       "counsel                1\n",
       "nolo contendere        1\n",
       "file                   1\n",
       "docket                 1\n",
       "impeachment            1\n",
       "magistrate judges      1\n",
       "panel                  1\n",
       "probation              1\n",
       "litigation             1\n",
       "affidavit              1\n",
       "Name: Terms, Length: 89, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Terms'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split the data into train & test sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df['Sents']\n",
    "y = df['Terms']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shaitender/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_split.py:605: Warning: The least populated class in y has only 1 members, which is too few. The minimum number of members in any class cannot be less than n_splits=3.\n",
      "  % (min_groups, self.n_splits)), Warning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('tfidf', TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=0.5, max_features=100, min_df=2,\n",
       "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
       "  ...2', random_state=None,\n",
       "           refit=True, scoring=None, solver='lbfgs', tol=0.0001, verbose=0))])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#vectorize the data, then train and fit a model\n",
    "import sklearn.decomposition\n",
    "import sklearn.feature_selection\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "#Build model\n",
    "'''model = Pipeline([\n",
    "                  ('tfidf', TfidfVectorizer(max_df=0.5, max_features=100,min_df=2, use_idf=True)), \n",
    "                  ('clf', LinearSVC()),\n",
    "                  ('classify', sklearn.linear_model.LogisticRegressionCV()),\n",
    "                                   \n",
    "])'''\n",
    "\n",
    "\n",
    "model = sklearn.pipeline.Pipeline([\n",
    "    #('pca', sklearn.decomposition.PCA()),\n",
    "    ('tfidf', TfidfVectorizer(max_df=0.5, max_features=100,min_df=2, use_idf=True)),\n",
    "    ('classify', sklearn.linear_model.LogisticRegressionCV()),\n",
    "    #('clf', LinearSVC()),\n",
    "])\n",
    "\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Form a prediction set\n",
    "predictions = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "#cm\n",
    "from sklearn import metrics\n",
    "print(metrics.confusion_matrix(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.19444444444444445\n"
     ]
    }
   ],
   "source": [
    "print(metrics.accuracy_score(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        precision    recall  f1-score   support\n",
      "\n",
      "             affidavit       0.00      0.00      0.00         1\n",
      "                answer       0.00      0.00      0.00         1\n",
      "                appeal       0.00      0.00      0.00         0\n",
      "           arraignment       0.00      0.00      0.00         1\n",
      "            bankruptcy       0.00      0.00      0.00         1\n",
      "       capital offense       0.00      0.00      0.00         1\n",
      "    charge to the jury       0.00      0.00      0.00         1\n",
      "             complaint       0.00      0.00      0.00         1\n",
      "            conviction       0.00      0.00      0.00         1\n",
      "               counsel       0.00      0.00      0.00         1\n",
      "                 court       0.20      0.88      0.33        16\n",
      "             defendant       0.00      0.00      0.00         4\n",
      "            deposition       0.00      0.00      0.00         1\n",
      "             discovery       0.00      0.00      0.00         1\n",
      "              evidence       0.00      0.00      0.00         3\n",
      "      federal question       0.00      0.00      0.00         1\n",
      "                felony       0.00      0.00      0.00         1\n",
      "               hearsay       0.00      0.00      0.00         1\n",
      "            indictment       0.00      0.00      0.00         1\n",
      "          instructions       0.00      0.00      0.00         1\n",
      "                 issue       0.00      0.00      0.00         2\n",
      "                 judge       0.00      0.00      0.00         4\n",
      "             judgement       0.00      0.00      0.00         2\n",
      "          jurisdiction       0.00      0.00      0.00         0\n",
      "                  jury       0.00      0.00      0.00         3\n",
      "               lawsuit       0.00      0.00      0.00         2\n",
      "            litigation       0.00      0.00      0.00         1\n",
      "               opinion       0.00      0.00      0.00         1\n",
      "         oral argument       0.00      0.00      0.00         1\n",
      "               parties       0.00      0.00      0.00         2\n",
      "             plaintiff       0.00      0.00      0.00         1\n",
      "                  plea       0.00      0.00      0.00         2\n",
      "             prosecute       0.00      0.00      0.00         1\n",
      "                record       0.00      0.00      0.00         1\n",
      "            settlement       0.00      0.00      0.00         1\n",
      "statute of limitations       0.00      0.00      0.00         1\n",
      "             testimony       0.00      0.00      0.00         2\n",
      "         u.s. attorney       0.00      0.00      0.00         1\n",
      "                uphold       0.00      0.00      0.00         1\n",
      "               verdict       0.00      0.00      0.00         2\n",
      "               witness       0.00      0.00      0.00         2\n",
      "\n",
      "           avg / total       0.05      0.19      0.07        72\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shaitender/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/shaitender/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Phrase_Extractor.pickle']"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pickle model\n",
    "from sklearn.externals import joblib\n",
    "joblib.dump(model, \"Phrase_Extractor.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
